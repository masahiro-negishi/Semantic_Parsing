{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import * \n",
    "from model import *\n",
    "from train import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field, form_field = generate_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_dataset('seq2seq_geoqueries/train.csv', 'csv', [(\"Text\", text_field), (\"Form\", form_field)], False)\n",
    "test_dataset = generate_dataset('seq2seq_geoqueries/test.csv', 'csv', [(\"Text\", text_field), (\"Form\", form_field)], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(train_dataset, min_freq=2)\n",
    "form_field.build_vocab(train_dataset, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_iterator = generate_iterator(train_dataset, batch_size, True)\n",
    "train_iterator_beam = generate_iterator(train_dataset, 1, True)\n",
    "test_iterator_beam = generate_iterator(test_dataset, 1, False, lambda x: len(x.Text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 200\n",
    "hid_dim = emb_dim\n",
    "# encoder = Encoder_Attention(emb_dim, hid_dim, len(text_field.vocab.stoi), device, 1, False, 0)\n",
    "# decoder = Decoder_Attention(emb_dim, hid_dim, len(form_field.vocab.stoi), device, 1, False, 0, 0)\n",
    "# seq2seq = Seq2Seq_Attention(encoder, decoder, device, form_field, 1.0)\n",
    "encoder = Encoder(emb_dim, hid_dim, len(text_field.vocab.stoi), device, 1, False, 0)\n",
    "decoder = Decoder(emb_dim, hid_dim, len(form_field.vocab.stoi), device, 1, False, 0, 0)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device, form_field, 1.0)\n",
    "model_path = \"models/epoch10000_batch10_lr1e-4_woatt_nodrop_ss00.pth\"\n",
    "seq2seq.load_state_dict(torch.load(model_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 280\n",
      "20 / 280\n",
      "30 / 280\n",
      "40 / 280\n",
      "50 / 280\n",
      "60 / 280\n",
      "70 / 280\n",
      "80 / 280\n",
      "90 / 280\n",
      "100 / 280\n",
      "110 / 280\n",
      "120 / 280\n",
      "130 / 280\n",
      "140 / 280\n",
      "150 / 280\n",
      "160 / 280\n",
      "170 / 280\n",
      "180 / 280\n",
      "190 / 280\n",
      "200 / 280\n",
      "210 / 280\n",
      "220 / 280\n",
      "230 / 280\n",
      "240 / 280\n",
      "250 / 280\n",
      "260 / 280\n",
      "270 / 280\n",
      "280 / 280\n",
      "Sentence level accuracy:  0.7035714285714286\n",
      "Bleu score: 0.8552917242050171\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_output_to_csv(seq2seq, test_iterator_beam, device, form_field, len(test_dataset), 'seq2seq_geoqueries/test_compare.csv', 'watt_e6000_b10_lr1e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 600\n",
      "20 / 600\n",
      "30 / 600\n",
      "40 / 600\n",
      "50 / 600\n",
      "60 / 600\n",
      "70 / 600\n",
      "80 / 600\n",
      "90 / 600\n",
      "100 / 600\n",
      "110 / 600\n",
      "120 / 600\n",
      "130 / 600\n",
      "140 / 600\n",
      "150 / 600\n",
      "160 / 600\n",
      "170 / 600\n",
      "180 / 600\n",
      "190 / 600\n",
      "200 / 600\n",
      "210 / 600\n",
      "220 / 600\n",
      "230 / 600\n",
      "240 / 600\n",
      "250 / 600\n",
      "260 / 600\n",
      "270 / 600\n",
      "280 / 600\n",
      "290 / 600\n",
      "300 / 600\n",
      "310 / 600\n",
      "320 / 600\n",
      "330 / 600\n",
      "340 / 600\n",
      "350 / 600\n",
      "360 / 600\n",
      "370 / 600\n",
      "380 / 600\n",
      "390 / 600\n",
      "400 / 600\n",
      "410 / 600\n",
      "420 / 600\n",
      "430 / 600\n",
      "440 / 600\n",
      "450 / 600\n",
      "460 / 600\n",
      "470 / 600\n",
      "480 / 600\n",
      "490 / 600\n",
      "500 / 600\n",
      "510 / 600\n",
      "520 / 600\n",
      "530 / 600\n",
      "540 / 600\n",
      "550 / 600\n",
      "560 / 600\n",
      "570 / 600\n",
      "580 / 600\n",
      "590 / 600\n",
      "600 / 600\n",
      "Sentence level accuracy:  0.6383333333333333\n",
      "Bleu score: 0.9134639501571655\n"
     ]
    }
   ],
   "source": [
    "evaluate(seq2seq, train_iterator_beam, device, form_field, len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 280\n",
      "20 / 280\n",
      "30 / 280\n",
      "40 / 280\n",
      "50 / 280\n",
      "60 / 280\n",
      "70 / 280\n",
      "80 / 280\n",
      "90 / 280\n",
      "100 / 280\n",
      "110 / 280\n",
      "120 / 280\n",
      "130 / 280\n",
      "140 / 280\n",
      "150 / 280\n",
      "160 / 280\n",
      "170 / 280\n",
      "180 / 280\n",
      "190 / 280\n",
      "200 / 280\n",
      "210 / 280\n",
      "220 / 280\n",
      "230 / 280\n",
      "240 / 280\n",
      "250 / 280\n",
      "260 / 280\n",
      "270 / 280\n",
      "280 / 280\n",
      "Sentence level accuracy:  0.44642857142857145\n",
      "Bleu score: 0.7708799839019775\n"
     ]
    }
   ],
   "source": [
    "evaluate(seq2seq, test_iterator_beam, device, form_field, len(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('semparse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0670093f5def8dbaf1c78569a448d0324e8e6700e913c889c09cd17129abd75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
